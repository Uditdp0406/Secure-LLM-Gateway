# ğŸ›¡ Secure LLM Gateway

A production-grade, secure, resilient, cost-aware LLM orchestration layer built with Node.js + Express.

=====================================================================

ğŸš€ HOW TO SWITCH FROM MOCK (DEVELOPMENT) â†’ PRODUCTION (REAL LLM)

=====================================================================

This project runs in two modes: Development (Mock) and Production (Real LLM).

---------------------------------------------------------------------
âœ… DEVELOPMENT MODE (NO API KEYS REQUIRED)
---------------------------------------------------------------------

The system runs fully using:
- Mock LLM provider
- Mock embeddings
- Redis (for rate limiting & caching)

You DO NOT need OpenAI or Anthropic keys.

Your `.env` should contain:

PORT=3000
NODE_ENV=development
GATEWAY_API_KEY=dev-gateway-key
REDIS_URL=redis://default:<password>@<host>:<port>
CACHE_ENABLED=true
RAG_ENABLED=true
USER_MAX_RPM=60
ADMIN_MAX_RPM=300
RATE_LIMIT_WINDOW_MS=60000

Use `"provider": "mock"` in your request body.

Example request:

{
  "prompt": "Explain JWT",
  "provider": "mock"
}

---------------------------------------------------------------------
ğŸš€ PRODUCTION MODE (REAL LLM PROVIDERS)
---------------------------------------------------------------------

To move to production:

1ï¸âƒ£ Add real provider API key

For OpenAI:
OPENAI_API_KEY=your_openai_key
OPENAI_DEFAULT_MODEL=gpt-4o
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

OR for Anthropic:
ANTHROPIC_API_KEY=your_anthropic_key

2ï¸âƒ£ Set environment:
NODE_ENV=production

3ï¸âƒ£ Restart server:
npm run dev

4ï¸âƒ£ Remove `"provider": "mock"` from request body.

The gateway automatically switches to real providers.
No code changes required.

=====================================================================

ğŸ“Œ WHAT THIS GATEWAY DOES

=====================================================================

This system sits between your application and LLM providers and adds:

- ğŸ” Authentication (API Key + JWT)
- âš¡ Distributed Rate Limiting (Redis)
- ğŸ›¡ Prompt Injection Guardrails
- ğŸ§  Hybrid RAG Engine
- ğŸ” Circuit Breaker Protection
- â± Global Timeout + Retry Logic
- ğŸ’° Cost Estimation
- ğŸ§® Token Counting
- ğŸ—„ Redis Response Caching
- ğŸ§ª Full Offline Mock Mode

=====================================================================

ğŸ§  REQUEST FLOW

=====================================================================

Client
  â†“
Authentication
  â†“
Rate Limiting (Redis)
  â†“
Guardrails
  â†“
RAG Engine (Optional)
  â†“
Redis Cache
  â†“
Circuit Breaker + Retry + Timeout
  â†“
Provider (OpenAI / Anthropic / Mock)
  â†“
Response (Cost + Metadata)

=====================================================================

ğŸ”¥ CORE CAPABILITIES

=====================================================================

ğŸ” Authentication
- Gateway API Key support
- JWT user support
- Role-based enforcement

âš¡ Distributed Rate Limiting
- Redis-backed
- Role-aware limits
- Configurable via `.env`

ğŸ§  Hybrid RAG Engine
- Document chunking
- Embedding generation
- Vector + keyword hybrid similarity
- Configurable alpha/beta weighting
- Mock-compatible

ğŸ›¡ Guardrails
- Prompt injection detection
- Unsafe pattern blocking

ğŸ” Resilience
- Circuit breaker per provider
- Automatic retry for transient errors
- Global timeout protection

ğŸ’° Cost Estimation
- Model-based token cost calculation

ğŸ§® Token Counting
- GPT tokenizer integration

ğŸ—„ Redis Caching
- Response caching
- Configurable TTL
- Cache bypass option

ğŸ§ª Mock Mode
- Mock LLM provider
- Mock embeddings
- Full system testable offline

=====================================================================

ğŸ“¦ INSTALLATION

=====================================================================

git clone <your-repo-url>
cd secure-llm-gateway
npm install

=====================================================================

âš™ï¸ ENVIRONMENT SETUP

=====================================================================

Create `.env` file in project root.

Minimum required:

PORT=3000
GATEWAY_API_KEY=dev-gateway-key
REDIS_URL=redis://default:<password>@<host>:<port>

=====================================================================

â–¶ RUNNING SERVER

=====================================================================

npm run dev

Server runs on:
http://localhost:3000

=====================================================================

ğŸ§ª TESTING

=====================================================================

Health Check:
GET /health

Completion:
POST /v1/completion

Headers:
Authorization: Bearer dev-gateway-key
Content-Type: application/json

Body:
{
  "prompt": "Explain JWT",
  "provider": "mock"
}

RAG Example:
{
  "prompt": "What is JWT?",
  "provider": "mock",
  "options": {
    "useRag": true
  }
}

=====================================================================

ğŸ“‚ PROJECT STRUCTURE

=====================================================================

src/
 â”œâ”€â”€ api/
 â”œâ”€â”€ gateway/
 â”œâ”€â”€ providers/
 â”œâ”€â”€ services/
 â”œâ”€â”€ utils/
 â””â”€â”€ index.js

=====================================================================

ğŸ“Š ENTERPRISE FEATURE CHECKLIST

=====================================================================

API Key Auth              âœ…
JWT Support               âœ…
Role-Based Limits         âœ…
Redis Rate Limiting       âœ…
Guardrails                âœ…
Circuit Breaker           âœ…
Retry Logic               âœ…
Global Timeout            âœ…
Cost Estimation           âœ…
Token Counting            âœ…
Redis Caching             âœ…
Hybrid RAG                âœ…
Mock Mode                 âœ…

=====================================================================

ğŸ— DESIGNED FOR

=====================================================================

- SaaS AI Platforms
- Multi-tenant LLM Systems
- Enterprise AI Infrastructure
- Secure API Proxying
- Cost-Controlled GenAI Deployments

=====================================================================

ğŸ VERSION

=====================================================================

v1.0 â€“ Production-Ready Secure LLM Gateway

=====================================================================

ğŸ¯ FINAL NOTE

=====================================================================

This is not a simple LLM wrapper.

This is a secure, resilient, scalable LLM orchestration layer designed for real-world production systems.
